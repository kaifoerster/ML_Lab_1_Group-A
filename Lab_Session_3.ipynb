{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaifoerster/ML_Lab_1_Group-A/blob/main/Lab_Session_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h1>Architecture design in neural networks</h2>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vzO4ORi0pnw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the data\n",
        "\n"
      ],
      "metadata": {
        "id": "THR6SWeqMYR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "# from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import display, clear_output\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "\n",
        "\n",
        "GLOBAL_RANDOM_STATE = 21\n",
        "tf.random.set_seed(GLOBAL_RANDOM_STATE)\n",
        "np.random.seed(GLOBAL_RANDOM_STATE)\n"
      ],
      "metadata": {
        "id": "vW8t4MQUpOfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.random.random((10**4, 10))\n",
        "X_train = tf.convert_to_tensor(X_train)\n",
        "\n",
        "Y_train = np.random.random((10**4,))\n",
        "Y_train = tf.convert_to_tensor(Y_train)"
      ],
      "metadata": {
        "id": "iQfjAF9oyAD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constructing the model\n"
      ],
      "metadata": {
        "id": "GT5-DpSRT1FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LazySequential(keras.models.Sequential):\n",
        "\n",
        "  def __init__(self, hidden_layers=10, activation_fn=tf.nn.relu):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    for i in range(hidden_layers):\n",
        "      self.add(keras.layers.Dense(2**3,\n",
        "                                  use_bias=False,\n",
        "                                  activation=activation_fn))\n",
        "\n",
        "    self.add(keras.layers.Dense(1))\n"
      ],
      "metadata": {
        "id": "13cY4sK5vwPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Online learning, minibatch and batch\n"
      ],
      "metadata": {
        "id": "Jsyj1KDJPF62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LazySequential(10)\n",
        "model.compile(optimizer=\"sgd\", loss=keras.losses.MeanSquaredError(), metrics=[\"acc\", \"mae\"])"
      ],
      "metadata": {
        "id": "fK1dMXEaS82h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_online = time.time()\n",
        "history_online = model.fit(X_train, Y_train, epochs=50, verbose=0)\n",
        "end_online = time.time()"
      ],
      "metadata": {
        "id": "ZPZsS_ST8hEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_full_batch = time.time()\n",
        "history_full_batch = model.fit(X_train, Y_train, batch_size=X_train.shape[0], epochs=50, verbose=0)\n",
        "end_full_batch = time.time()"
      ],
      "metadata": {
        "id": "FSUZaT7TKiDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_mini_batch = time.time()\n",
        "history_mini_batch = model.fit(X_train, Y_train, batch_size=2**5, epochs=50, verbose=False)\n",
        "end_mini_batch = time.time()"
      ],
      "metadata": {
        "id": "NichHANBuCAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: plot loss over time and print computational time of the three variations."
      ],
      "metadata": {
        "id": "sqz3DnSHXpYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "fig, ax = plt.subplots(1, 3, figsize=(30, 5))\n",
        "\n",
        "batch_size = [\"full_batch\", \"mini_batch\", \"online\"]\n",
        "\n",
        "for i in range(3):\n",
        "  size = batch_size[i]\n",
        "  start = globals()[f\"start_{size}\"]\n",
        "  end = globals()[f\"end_{size}\"]\n",
        "  history = globals()[f\"history_{size}\"].history\n",
        "\n",
        "  print(f\"Total training time for {size} over 50 epochs: {(end - start):.1f} seconds.\")\n",
        "\n",
        "  ax[i].plot(history['loss'])\n",
        "  ax[i].set_title(f\"Loss curve: {size}\")\n"
      ],
      "metadata": {
        "id": "XykSrZkWLzaM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vanishing gradient"
      ],
      "metadata": {
        "id": "-CyTeBMjOwz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gradient_updates(model, x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(x)\n",
        "    loss = model.compute_loss(y=y, y_pred=predictions)\n",
        "\n",
        "  gradient_updates = tape.gradient(loss, model.trainable_variables)\n",
        "  return gradient_updates"
      ],
      "metadata": {
        "id": "KYtqQSRg9B_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "big_model = LazySequential(50, activation_fn=tf.nn.tanh)\n",
        "big_model.compile(optimizer=\"sgd\", loss=keras.losses.MeanSquaredError())"
      ],
      "metadata": {
        "id": "n5ua-tP5OtUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: compute the sum of the absolute weights for hidden layers 1 to 25 and for hidden layers 25 to 50 (remember to avoid first and output layer)."
      ],
      "metadata": {
        "id": "TNW7-60yWXhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "sum1 = sum([ tf.math.reduce_sum( tf.abs(grad_updates[i]) ).numpy() for i in range(1,26) ])\n",
        "sum2 = sum([ tf.math.reduce_sum( tf.abs(grad_updates[i]) ).numpy() for i in range(26, 51) ])\n",
        "\n",
        "print(f\"Absolute sum of weights for the first half of the hidden layers: {sum1: .1f}\")\n",
        "print(f\"Absolute sum of weights for the second half of the hidden layers: {sum2: .1f}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "z9sl-fZGTup_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c34ca5b6-123c-46ed-8e3c-dd0d29f93923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolute sum of weights for the first half of the hidden layers:  46.0\n",
            "Absolute sum of weights for the second half of the hidden layers:  28.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: plot heatmaps of the gradient updates for the gradient: do you recognize a pattern?"
      ],
      "metadata": {
        "id": "aWrQNqrkQa5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "grad_updates = get_gradient_updates(big_model, X_train, Y_train)\n",
        "\n",
        "for i in range(len(grad_updates)):\n",
        "  grad_update = grad_updates[i]\n",
        "  try:\n",
        "    if len(grad_update.shape) == 2 and grad_update.shape[1] != 1:\n",
        "      heatmap = sns.heatmap(grad_update * 10**3, vmin=-100, vmax=100,\n",
        "                            annot=True, cmap='coolwarm', fmt='.1f')\n",
        "\n",
        "      plt.suptitle(f\"Layer {i}\")\n",
        "      plt.show()\n",
        "      time.sleep(1)\n",
        "      clear_output(wait=True)\n",
        "  except:\n",
        "    continue"
      ],
      "metadata": {
        "id": "SWZznWnMG1_D",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning\n",
        "\n"
      ],
      "metadata": {
        "id": "uEenH2AkPYXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_tuner"
      ],
      "metadata": {
        "id": "N-Oc5qwO4IXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner"
      ],
      "metadata": {
        "id": "FllVGhj57tKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "  model.add(keras.layers.Dense(1))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "  mse = keras.losses.MeanSquaredError()\n",
        "  model.compile(optimizer=keras.optimizers.SGD(learning_rate=hp_learning_rate),\n",
        "                loss=mse,\n",
        "                metrics=[mse])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "P8--5eKf-7jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = keras_tuner.RandomSearch(model_builder, objective=\"val_loss\", max_trials=10, seed=GLOBAL_RANDOM_STATE, overwrite=True)"
      ],
      "metadata": {
        "id": "XZGLk_Z-7mkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, Y_train, epochs=10, validation_split=0.2)"
      ],
      "metadata": {
        "id": "TNyzFGR4_4db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d1ab27b-5050-492f-8f23-8b159666f3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 11s]\n",
            "val_loss: 0.08940134942531586\n",
            "\n",
            "Best val_loss So Far: 0.08330491185188293\n",
            "Total elapsed time: 00h 01m 29s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp = tuner.get_best_hyperparameters()[0]"
      ],
      "metadata": {
        "id": "qLHA2uVaAP5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: build an HyperModel constructor that implements a Neural Network with 4 layers in a funnel-fashioned way:\n",
        "# the first layer will have no. of units of the best model from step 1. The output size\n",
        "# of the other layers will be a tunable hyperparameter of a smaller size than the output size of the previous layer.\n",
        "# use learning rate from the best model and fine-tune with RandomSearch on our random dataset"
      ],
      "metadata": {
        "id": "mDgclxq7DTsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def funnel_model_builder(hp, best_hp):\n",
        "\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(keras.layers.Dense(best_hp[\"units\"]))\n",
        "\n",
        "  for i in range(3):\n",
        "      last_layer_shape = model.layers[-1].units\n",
        "      model.add(keras.layers.Dense(units=hp.Int(f\"unit_{i+1}_layer\", 1, last_layer_shape)))\n",
        "\n",
        "  model.add(keras.layers.Dense(1))\n",
        "  model.compile(loss=keras.losses.MeanSquaredError(), optimizer=\"sgd\")\n",
        "  mse = keras.losses.MeanSquaredError()\n",
        "  model.compile(optimizer=keras.optimizers.SGD(learning_rate=best_hp[\"learning_rate\"]),\n",
        "                loss=mse,\n",
        "                metrics=[mse])\n",
        "  return model"
      ],
      "metadata": {
        "id": "PWy4TrXGBT1L",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "tuner_depth = keras_tuner.RandomSearch(lambda hp: funnel_model_builder(hp, best_hp),\n",
        "                                       objective=\"val_loss\",\n",
        "                                       max_trials=10,\n",
        "                                       seed=GLOBAL_RANDOM_STATE,\n",
        "                                       overwrite=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2GoDQrhBCqke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "tuner_depth.search(X_train, Y_train, epochs=10, validation_split=0.2)"
      ],
      "metadata": {
        "id": "xeMCVxyGC4lK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}